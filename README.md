# ğŸ•·ï¸ Scrapper Chatbot Services

Este proyecto proporciona una API REST construida con Flask que permite realizar scraping de contenido web para alimentar un chatbot. 
La arquitectura estÃ¡ diseÃ±ada para ser modular y escalable, facilitando la integraciÃ³n de nuevos contextos y fuentes de datos.

---

## ğŸ“ Estructura del Proyecto

scrapper_chatbot_services/
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ routes.py
â”‚ â””â”€â”€ utils.py
â”œâ”€â”€ context/
â”‚ â””â”€â”€ [archivos de contexto]
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ run.py

- `app/`: Contiene la lÃ³gica principal de la aplicaciÃ³n, incluyendo las rutas y funciones auxiliares.
- `context/`: Almacena archivos relacionados con diferentes contextos para el scraping.
- `run.py`: Punto de entrada para ejecutar la aplicaciÃ³n Flask.
- `Dockerfile`: ConfiguraciÃ³n para construir una imagen Docker de la aplicaciÃ³n.
- `requirements.txt`: Lista de dependencias necesarias para ejecutar la aplicaciÃ³n.

---

## ğŸš€ InstalaciÃ³n y EjecuciÃ³n

### ğŸ”§ Requisitos Previos

- Python 3.9 o superior
- Git
- (Opcional) Docker y Docker Compose

### ğŸ“¥ Clonar el Repositorio

```bash
git clone https://github.com/JehielL/scrapper_chatbot_services.git
cd scrapper_chatbot_services
ğŸ Configurar el Entorno Virtual
En Linux/macOS:
python3 -m venv venv
source venv/bin/activate
En Windows:
python -m venv venv
venv\Scripts\activate
ğŸ“¦ Instalar las Dependencias
pip install -r requirements.txt
â–¶ï¸ Ejecutar la AplicaciÃ³n
bash

python run.py
La aplicaciÃ³n estarÃ¡ disponible en http://127.0.0.1:5000

ğŸ³ Uso con Docker (Opcional)
ğŸ“¦ Construir la Imagen Docker
docker build -t scrapper_chatbot_services .
ğŸš€ Ejecutar el Contenedor
docker run -d -p 5000:5000 scrapper_chatbot_services

La API estarÃ¡ accesible en http://localhost:5000

ğŸ“¡ Endpoints Principales
GET /scrape: Inicia el proceso de scraping para una URL especÃ­fica.

GET /contextos: Devuelve la lista de contextos disponibles.

POST /set_contexto: Permite establecer un nuevo contexto para el scraping.

âš ï¸ Nota: La implementaciÃ³n detallada de estos endpoints se encuentra en app/routes.py.

ğŸ§ª Pruebas
Actualmente, no se han implementado pruebas automatizadas. Se recomienda utilizar herramientas como pytest para agregar pruebas unitarias y de integraciÃ³n en el futuro.

ğŸ¤ Contribuciones
Las contribuciones son bienvenidas. Por favor, sigue los siguientes pasos:

Haz un fork del repositorio.

Crea una nueva rama (git checkout -b feature/nueva-funcionalidad).

Realiza tus cambios y haz commits descriptivos.

EnvÃ­a un pull request detallando los cambios realizados.

ğŸ“„ Licencia

